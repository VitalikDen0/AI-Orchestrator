# AI Orchestrator

**Интеллектуальный мультимодальный AI-помощник с системной интеграцией**

Комплексное решение для автоматизации задач, объединяющее возможности больших языковых моделей, computer vision, распознавание речи, генерацию изображений и системное управление через единый интерфейс.

## ✅ Реализованные функции

### Мультимодальный ИИ
- Текстовая модель‑мозг: прямая интеграция с LM Studio API, автозагрузка модели при старте, получение короткого ID, проверка статуса и контекст‑параметров модели через /v1/models и /v1/chat/completions.
- Computer Vision: обработка изображений через “moondream2-llamafile” с передачей base64‑картинок и детальным описанием содержимого сцены.
- Распознавание речи: Whisper CLI (whisper.cpp) с авто‑проверкой наличия бинарника и модели, опциональным выделением вокала через audio‑separator (Demucs), конвертацией в WAV через ffmpeg и безопасным логированием результатов.
- Генерация изображений: прямая интеграция со Stable Diffusion через diffusers (StableDiffusionPipeline.from_single_file), настройка DPMSolverMultistepScheduler, авто‑выбор CUDA/CPU, seed, шаги, размеры, сохранение файлов и возврат base64.
- Генерация видео (бета): ключевые кадры с разными seed, плавная интерполяция между ними, сборка через imageio.mimsave, настройка кадров/частоты/шага, сохранение PNG кадров и итогового MP4.

### Системная интеграция
- PowerShell команды: выполнение с автоисправлением “&&” в PowerShell‑совместимый синтаксис (Push‑Location/“;”), тайм‑аутом, cp1251‑декодированием и подробным логом возврата.
- Управление мышью и клавиатурой: перемещение, клики ЛКМ/ПКМ, прокрутка, зажатие/отжатие, drag&drop, ввод текста с pyautogui и координационными действиями.
- Скриншоты и анализ экрана: mss с даунскейлом до 1280×720 и PNG base64, fallback на pyautogui при отсутствии mss.
- Проверки окружения: детект и логирование наличия ffmpeg, автозапуск модели в LM Studio с передачей пути к .gguf.

### Интернет и коммуникации
- Google Search API: выполнение запросов к CSE, сбор сниппетов и попытка получить часть контента страниц (до 2000 символов) для последующего анализа.
- YouTube интеграция: проверка VPN (ifconfig.me), валидация cookies, три каскада параметров для yt‑dlp (Android/Web/простые), скачивание видео и аудио, проверка доступности ссылки и получения метаданных (title, duration, uploader).
- Telegram‑бот: проверка токена, обработка текста/фото/аудио, ответ с транскрипцией, описание изображений и отправка сгенерированных картинок обратно в чат.
- Веб‑интерфейс: запуск FastAPI‑сервера webui.server:app через uvicorn по флагу --web с отключением локального показа изображений.

### Управление ресурсами
- Smart Resource Management: автоматическое включение инструментов (vision/audio/image_generation) по требованию и авто‑выключение через 5 минут отдельными таймерами на потоках.
- Динамический контекст‑менеджмент: получение реального размера контекста из ответов модели (usage.total_tokens), три уровня обрезки истории (приближение/безопасный/критический), оценка safe_context/max_context и адаптивная пересборка сообщений.

### Продвинутые возможности
- Покадровый анализ видео: извлечение кадров через ffmpeg, описание каждого кадра vision‑моделью, группировка одинаковых описаний в диапазоны таймкодов “[start‑end]” либо списки “[t1, t2]”.
- Синхронизация аудио/видео: формирование общего “brain_input” с [Покадровое описание видео] и [Текст из аудио] для контекстного ответа модели.
- Умный JSON‑парсер: извлечение JSON из свободного текста и think‑блоков, автокоррекции (баланс скобок, заменa кавычек, удаление лишних запятых, кавычки вокруг ключей, очистка неASCII), итеративный обработчик цепочек действий без рекурсии.
- Автоустановка зависимостей: on‑demand установка diffusers/transformers/torch/accelerate/safetensors при первом обращении к генерации.

### Система мониторинга и логирования
- Подробное логирование: файл и консоль с фильтром телеметрии (включая подавление шумных сообщений chromadb), отдельные уровни для консоли/файла, единая метрика действий.
- Метрики и экспорт: сбор времени действий, средние значения, последние операции, экспорт статистики и контекст‑инфо в JSON по команде “export”.

### AI‑генерация контента
- Автогенерация промптов: вспомогательный запрос к “мозгу” для построения англоязычного JSON промпта для SD, строгая валидация языка и подстановка негативных промптов по умолчанию при необходимости.
- Параметризация и результаты: управление seed/steps/size/CFG, сохранение изображений и видео, возврат base64, авто‑открытие результата в ОС где возможно.
- Голос ИИ (бета): озвучка важных фрагментов через gTTS с авто‑воспроизведением (pygame mixer) и fallback на системный плеер; действие “speak” c правилом “озвучивать только самое важное”.

### Интеграция и совместимость
- LM Studio API: полная интеграция с загрузкой/проверкой моделей и передачей сообщений в /v1/chat/completions.
- Конвертация форматов: аудио в WAV через ffmpeg, универсальные вспомогательные конвертеры и безопасные попытки fallback.
- Поддержка CUDA/CPU: авто‑детект CUDA и перевод пайплайна на GPU при наличии, лог доступной VRAM и имени GPU для ChromaDB.
- Windows‑ориентированность: выполнение системных команд через PowerShell и корректная работа путей/кодировок, предусмотрено веб‑ и Telegram‑использование.

### Документы и RAG
- Чтение документов: DOCX (python‑docx), Excel (pandas/openpyxl, все листы), PDF (PyPDF2), CSV, с конвертацией содержимого в текст и защитой от пустых данных.
- RAG для больших файлов: оценка объёма, разбиение по предложениям на части, сборка первых фрагментов с указанием общего числа частей, опциональный вывод по запросу.
- Генерация файлов: DOCX/Excel/Markdown/PDF из текстового контента, сохранение в output, единый универсальный интерфейс generate_file.

### Память и персонализация
- Векторная память (ChromaDB): добавление диалогов/предпочтений с эмбеддингами SentenceTransformer, поиск похожих диалогов с адаптивным порогом, извлечение релевантного контекста для ответа.
- Работа с предпочтениями: извлечение из текста пользователя и подтверждений ИИ, краткое резюме предпочтений, очистка старых записей и статистика БД.

### Дополнительно (бета/экспериментально)
- Постоянная голосовая запись (потоки): очередь аудио‑чанков и воркер обработки; архитектурно предусмотрено для веб‑интерфейса, реализация захвата аудио вынесена за рамки скрипта.

p.s. этот текст обновляется реже, все изменения сначала пишутся в Новые функции, а после через время как их накопится некоторое кол-во, добавляются выше.

## 📋 Требования

### Аппаратные требования 
*У меня есть идеи решения этой проблемы, через Google Colab, но это уже не будет "приватность" как было бы, если все вычисления делались прямо на устройстве. Будет переключаемая фунция, кто хочет пользоваться, но нет вычислительных ресурсов и кому не так страшно, что будут использоваться облачные ресурсы*

- **Минимум**: 16GB RAM для комфортной работы со всеми инструментами, дискретная видеокарта с 8GB VRAM если не требуется запускать несколько инструментов
- **Рекомендуется**: 32GB RAM, RTX 4070/4080 или аналогичная с 12-16GB VRAM

### Программное обеспечение

- Python 3.10+ (Использовалась 3.10.11)
- LM Studio 0.3.23+ (с моделями) (указана последняя версия LM Studio, скорее всего не обязательно последняя)
- ffmpeg (для работы с аудио/видео)
- yt-dlp (для YouTube)
- PowerShell (Windows)


### Библиотеки Python

```bash
# Создание виртуальной среды
python -m venv venv

# Активация (Windows)
venv\Scripts\activate

# Установка зависимостей
pip install -r requirements.txt
```

## 🚀 Установка и настройка

### 1. Установка моделей

#### Основная модель (мозг)

- **huihui-qwen3-4b-thinking-2507-abliterated** (использовалась Q4_K_S)
- Скачайте через LM Studio или на [Hugging Face](https://huggingface.co/mradermacher/Huihui-Qwen3-4B-Thinking-2507-abliterated-GGUF)
- Требования: ~4GB VRAM
p.s. **abliterated** по причине того, что она будет меньше отказывать в действиях

#### Audio модель

- **[whisper-large-v3-q8_0](https://huggingface.co/vonjack/whisper-large-v3-gguf)** (Использовал Q8)
- Требования: ~4GB VRAM
#### Vision модель

- **[moondream2-050824](https://huggingface.co/cjpais/moondream2-llamafile/blob/main/moondream2-050824-q8.gguf)**
- Требования: ~2GB VRAM


#### Stable Diffusion модель (аниме модели)

- **novaAnime_v20**: [CivitAI](https://civitai.com/models/328365) (~4GB VRAM) (проблема с пальцами, SD 1.5)
- **Альтернативная улучшенная**: [CivitAI](https://civitai.com/models/827184) (~8GB VRAM) (мой личный фаворит, очень нравится, SDXL)
- **LoRA для улучшения**: [Detail Tweaker LoRA](https://civitai.com/models/58390) (настройки: strength=2) (можно и без нее, результат вряд ли заметите, используйте еще LoRA на фикс пальцев)

<table>
  <tr>
    <td><img src="https://github.com/user-attachments/assets/e21db971-0cfa-4d7f-969d-589ce1f42030" width="100%"/></td>
    <td><img src="https://github.com/user-attachments/assets/bbe62c62-8570-49cc-9186-9d428099aa8f" width="100%"/></td>
  </tr>
  <tr>
    <td><img src="https://github.com/user-attachments/assets/667ad7b2-7d4a-4ff2-9b26-74d3967f2228" width="100%"/></td>
    <td><img src="https://github.com/user-attachments/assets/83966705-d90a-4235-9719-504963ad9bff" width="100%"/></td>
  </tr>
</table>

Это примеры генерации novaAnime_v20 без явного указания деталей (нейросеть сама поставит нужное)

### 2. Настройка переменных окружения

Создайте файл `.env` в корневой папке:

```env
# Google Search API
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_CSE_ID=your_custom_search_engine_id_here

# Telegram Bot (опционально)
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here
TELEGRAM_ALLOWED_USER_ID=your_telegram_user_id_here

# Пути к программам
LMSTUDIO_EXE=C:\Program Files\LM Studio\LM Studio.exe
STABLE_DIFFUSION_MODEL_PATH=J:\ComfyUI\models\checkpoints\novaAnime_v20.safetensors
```


### 3. Настройка путей в коде

Обновите пути к моделям в файле `1.py`:

```python
self.brain_model = "путь_к_вашей_qwen_модели.gguf"
```

Создайте структуру папок:

```
проект/
├── Photos/          # Для загружаемых изображений
├── Audio/           # Для аудиофайлов
├── Video/           # Для видеофайлов
├── Images/          # Для сгенерированных изображений
├── Videos/          # Для сгенерированных видео
├── Release/         # Для whisper-cli.exe 
├── models/          # Для whisper-модели
├── Docx/            # Для работы с DOCX файлами
├── Excel/           # Для работы с EXCEL файлами
├── PDF/             # Для работы с PDF файлами
├── output/          # Для выходных файлов после генерации
└── webui/static/    # Для веб-интерфейса
```


## 💻 Использование

### Консольный режим

```bash
python 1.py
```


### Веб-интерфейс

```bash
python 1.py --web
```

Затем откройте http://127.0.0.1:8001/

### Telegram бот

После настройки токена в `.env`, бот запустится автоматически при запуске основного скрипта. (не спамит в консоль о своей работе, только при *--web*)

## В разработке

- На данный момент идет разработка поддержки работы с Google Colab

## Новые функции (бета-тест, мало тестировались/не тестировались)

- Сделал обработку Docx, excel и других файлов, которые уже были ранее, сделал это не при инициализации, а только по требованию.
- И до кучи сделал RAG, вот он тестировался, но прям полноценную правильную работу я пока не гарантирую
- Добавлена обработка PDF
- Генерация файлов... Там много каких, пока все кроме Video... Да, я сутки потратил и так и не смог реализовать нормально работу с SDXL моделями, а потом работающую сборку на SD1.5 случайно сломал и теперь вообще не знаю что делать...
- OCR реализовано, работает хорошо, сделал интеграцию много куда, во все документы, где может быть текст и при распознавании видео, если vision модель вернет информацию о том, что на изображении был текст, автоматически применится, если пользователь указал о наличии на изображении текста, будет сразу применено распознавание.
- Улучшен Debug через нейросеть, если случаются проблемы при выполнении инструментов и подобное, она не будет выдумывать, скажет что есть такая то проблема (обнаружено после попытки распознать текст, выдавала несуществующий текст, будьте бдительны, нейросети ошибаются)
- Добавил то, что сразу надо было, обновил загрузку файлов через телеграмм. Не тестировал

## 🗺️ Планы развития (чем выше, тем больше приоритет)

- [ ] **Ансамбль моделей**: Запуск единовременно нескольких моделей, чтобы спорить между друг другом, чтоы выдавать более качественные ответы (не факт)
- [ ] **Self-reflection**: Обучение на своих ошибках и запись их в DB
- [ ] **Аудит всех действий**: И отмена, если что-то пошло не так (пока не знаю как, но буду думать)
- [ ] **Система триггеров на события**: И планировщик задач
- [ ] **Работа с Email**: Работа с почтовой системой Gmail и Mail (в дальнейшем будут дополняться, но это будут основные)
- [ ] **Cloud storage**: Работа с Google Drive и другими облачными хранилищами
- [ ] **Немного для контент креаторов**: Это будет плагин, лично я не хочу создавать отдельную программу для этого, я слишком ленивый, в общем хочу научить... Быть стримером? Думаю я потрачу много времени на это, платформа будет ТОЛЬКО Twitch, по крайней мере я точно после реализации долгое время трогать другие платформы не буду.
- [ ] **Ролевая система доступа**: Если будут использовать нейросеть несколько человек
- [ ] **Генерация img2img**: Из названия понятно
- [ ] **Музыка/аудио генерация**: Будет эксперимент наряду с Видео
- [ ] **Расширенная генерация видео**: Полное тестирование и оптимизация
- [ ] **Улучшенное распознавание видео**: Стабилизация функций анализа
- [ ] **Интеграция с LoRA**: Вообще это было реализовано, но после было вырезано из-за ненадобности, но теперь снова нужно вернуть. Так же возможно будет интеграция с clip, wae, etc.
- [ ] **Predictive analytics**: Теоретически для ускорения работы, на практике все зависит от моей реализации
- [ ] **Интеграция с GitHub**: Пока заметка
- [ ] **Нативное GUI приложение**: По типу LM Studio или Ollama
- [ ] **Управление браузером**: Ну только Chromium. А еще я пока только представил, идейно это будет как браузер Comet, но только работа через локальную LLM и кэширование и сохранение в долговременную память, вместо передачи своей личной информации на сервера того же Perplexity. Идея амбициозная, но получится ли ее реализовать? P.s. Я не специально реализую систему плагинов, чего изначально не хотел, но так как это не каждому нужно будет, я сделаю возможность работы и без этого плагина. Начало разделения монолита... Развалится как...
- [ ] **Sandbox для команд**: Сделаю необязательным, так как моя цель была изначально не изолировать команды, но будет возможность настроить этот параметр. Возможно сделаю фильтр определенных команд для выполнения их в песочнице
- [ ] **Улучшение в области математики**: Пока мысленные наброски
- [ ] **Enterprise функции**: Для коммерческих решений, это будет, но не сейчас и не в таком виде.
- [ ] **Linux**: Да линукс юзеры, я попробую адаптировать код под Linux, но я плохо шарю за ваши Unix системы, тем более их очень много и скорее всего каждая отличается, в общем не гарантирую, но возможно это будет
- [ ] **Нормальный код**: Сделать не монолитным кодом, где все в одном файле, а распределить по нескольким
- [ ] **Криптовалюта**: ???
- [ ] **IoT устройства**: Интеграция с умным домом (у самого ничего подобного нет, возможно реализации не будет, но тут посмотрим, если востребовано будет, реализация будет)

## ⚠️ Известные ограничения

### В разработке

- **Web интерфейс**: Web интерфейс достаточно сильно отстает от реализации через консоль, это будет позже поправлено. Попробую сделать его по лучше, хотя я не очень хочу, так как буду пробовать переходить к нативному GUI и попробую отказаться от Web, но там как пойдет
- **Генерация видео**: Функция реализована, но находится в стадии тестирования (к сожалению мой пк слишком слаб, плюс пока не понимаю как правильно такое сделать, ни в AUTOMATIC1111, ни в ComfyUI не получилось нормально реализовать. Fun Fact, ранее генерация изображений была через AUTOMATIC1111, потом я понял что слишком неоптимизированно, перешел на ComfyUI и так и не смог разобраться, вечная Ernno 22)
  Update: Решена проблема, скорее всего будет интеграция с ComfyUI, сейчас нужно около 14GB VRAM. Конечно это не то, чего я ожидал от видео, но и так сойдет, у тех кого более мощные пк смогут поставить модели лучше. Update: реализовано, но пока на второй план, есть мысли по интереснее. Я все сломал, так же я так и не смог решить проблемы с SDXL моделями и нестабильно работают SD 1.5, а SVD это совершенно не то, что я хочу, да оно работает... Но это не то, там нельзя задавать промт, нейросеть сама решает что анимировать и в этом проблема.
- **Распознавание видео**: Экспериментальная функция, не полностью протестирована (не было нужны :] )
- **Переработка кода**: ~~Пересел на другую IDE и почему-то ранее мне компилятор не показывал проблемы, сейчас их в коде +-100, но код выполняет свою задачу. Некоторое время уйдет на исправления может не всех, но большинства проблем, так же улучшу код на безопасность выполнения кода. (Bruh). Update: проделано много работы, но скорее всего не конец, вижу большую проблему, как решить пока не знаю. Осталась последняя проблема.~~ Все основные проблемы решены, осталось разобраться пока что с ChromaDB что не так, а после завезу поддержку видео, к сожалению с привязкой к ComfyUI пока не пойму как сделать без него.

### Текущие проблемы

- **Проблема оптимизации промта**: Пришел к выводу, что я разделю промт на несколько частей, где основной промт теперь не будет составлять 6666 токенов (да, ровно 6666 на данный момент), а примерно 1000. Будет разделение, нейросети скормлится только самое важное, правила и какие есть инструменты, если модели нужны будут инструменты, она сможет их вызвать с помощью специального флага, сначала инструмент расскажет как с ним работать, а потом нейросеть уще раз уже использует инструмент, зная что от нее хотят и как с этим инструментом работать. Думаю поможет немного со скоростью ответов. Относительно скоро возможно начнется разделение всего этого монолита на отдельные файлы, но лично я сам думаю что вряд ли это будет. По крайней мере это почти самое последнее что я хочу делать.
- **LM Studio API**: После версии 0.3.23 возникает проблема с показом активных моделей (более не влияет, но все еще не удобно)
- **Возможны проблемы с Cookie**: для скачивания Youtube видео я использовал Cookie, я уже не помню, нужны или нет, позже если что добавлю скрипт на получение Cookie, но для людей не из России проблем не будет, так как там несколько способов скачать видео.

## **Возможные** вопросы - ответы:

- Почему LM Studio?
- Под капотом есть все нужное, не нужно мучаться с библиотеками, настройками и тп. Код вполне можно переписать и без использования LM Studio, но мне это не нужно, может в будущем...

## 🤝 Вклад в разработку

Проект создан российским разработчиком с использованием современных AI-технологий. Приветствуются вопросы, предложения и помощь в развитии на любых языках.
Характеристики ПК:

- 5060 TI Palit Infinity 16GB VRAM
- Intel i5-7400 3.00GHz
- 32GB RAM DDR4 2400MHz

## 📝 Лицензия

**Dual License модель**:

- **Open Source версия**: GPL-3.0 для персонального использования
- **Commercial License**: Свяжитесь для коммерческого использования

## 🎯 AI-Assisted Development

Этот проект был создан с использованием современных AI-инструментов (Claude, GPT) для:

- Генерации и оптимизации кода
- Архитектурных решений
- Документации и тестирования

Все AI-сгенерированный код был тщательно проверен, протестирован и адаптирован разработчиком-человеком.

***

**Поддержать проект**:

- GitHub Sponsors: `later`
- DonationAlerts: `later`
<span style="display:none"></span>

И да, у меня main.py это 1.py. 
Ну и это не финальная версия README
