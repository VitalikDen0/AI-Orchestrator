"""Image generation manager for Stable Diffusion models and LoRA."""

from __future__ import annotations

import json
import logging
import os
import sys
import subprocess
import time
import random
from typing import Any, Dict, List, Optional, Tuple, Union

from PIL import Image

logger = logging.getLogger(__name__)


def install_diffusers_dependencies():
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è diffusers
    """
    required_packages = [
        "diffusers", 
        "transformers", 
        "accelerate", 
        "safetensors", 
        "peft",
        "omegaconf"
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        logger.info(f"üì¶ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–∞–∫–µ—Ç—ã: {', '.join(missing_packages)}")
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install"] + missing_packages)
            logger.info("‚úÖ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π: {e}")


class ImageGenerator:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Stable Diffusion
    """
    
    def __init__(self, model_manager: ModelManager):
        self.model_manager = model_manager
        self.current_pipeline = None
        self.logger = logger

    def generate_image(self, prompt: str, negative_prompt: str, params: dict) -> Optional[str]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –ø—Ä—è–º—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å–æ Stable Diffusion
        """
        start_time = time.time()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.logger.info(f"üîß –ü–æ–ª—É—á–µ–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: prompt='{prompt[:50]}...', negative_prompt='{negative_prompt}'")
        
        # –ì–æ—Ä—è—á–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ LoRA
        self.model_manager.get_lora_config(force_reload=True)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ ModelManager
        model_path = self.model_manager.get_model_path()
        if not model_path:
            self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ Stable Diffusion –º–æ–¥–µ–ª—å")
            return None
        
        if not os.path.exists(model_path):
            self.logger.error(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
            return None
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏
        model_type = self.model_manager.detect_model_type(model_path)
        self.logger.info(f"üîç –û–ø—Ä–µ–¥–µ–ª–µ–Ω —Ç–∏–ø –º–æ–¥–µ–ª–∏: {model_type} –¥–ª—è {os.path.basename(model_path)}")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º LoRA —Ç—Ä–∏–≥–≥–µ—Ä—ã –∫ –ø—Ä–æ–º–ø—Ç—É
        enhanced_prompt = self.model_manager.apply_lora_triggers(prompt, model_type)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        default_params = {
            "seed": -1,
            "steps": 30,
            "width": 1024,
            "height": 1024,
            "cfg": 7.0,
            "sampler_name": "dpmpp_2m",
            "scheduler": "karras"
        }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        gen_params = default_params.copy()
        gen_params.update(params)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º seed –µ—Å–ª–∏ –æ–Ω -1
        if gen_params["seed"] == -1:
            gen_params["seed"] = random.randint(0, 2**32 - 1)
            self.logger.info(f"üé≤ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Å–ª—É—á–∞–π–Ω—ã–π seed: {gen_params['seed']}")
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ –¥–ª—è SD 1.5
        model_name = os.path.basename(model_path).lower()
        is_sdxl = any(keyword in model_name for keyword in ['xl', 'sdxl', 'illustrious', 'pony'])
        
        if not params.get("width") and not params.get("height"):
            if not is_sdxl:
                gen_params["width"] = 512
                gen_params["height"] = 512
                self.logger.info("üìê –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–∏–ª —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è SD 1.5 –º–æ–¥–µ–ª–∏: 512x512")
        
        self.logger.info(f"üîß –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {gen_params}")
        
        try:
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            install_diffusers_dependencies()
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
            from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion import StableDiffusionPipeline  # type: ignore
            from diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl import StableDiffusionXLPipeline  # type: ignore
            from diffusers.schedulers.scheduling_dpmsolver_multistep import DPMSolverMultistepScheduler  # type: ignore
            import torch
            
            self.logger.info(f"üì¶ –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å: {model_path}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π pipeline
            if is_sdxl:
                self.logger.info("üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ SDXL –º–æ–¥–µ–ª—å, –∏—Å–ø–æ–ª—å–∑—É—é StableDiffusionXLPipeline")
                pipe = StableDiffusionXLPipeline.from_single_file(
                    model_path,
                    torch_dtype=torch.float16,
                    use_safetensors=True
                )
            else:
                self.logger.info("üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ SD 1.5 –º–æ–¥–µ–ª—å, –∏—Å–ø–æ–ª—å–∑—É—é StableDiffusionPipeline")
                pipe = StableDiffusionPipeline.from_single_file(
                    model_path,
                    torch_dtype=torch.float16,
                    use_safetensors=True
                )
            
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–∞ GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            if torch.cuda.is_available():
                pipe = pipe.to("cuda")
                self.logger.info("üöÄ –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–º–µ—â–µ–Ω–∞ –Ω–∞ GPU")
            else:
                self.logger.warning("‚ö†Ô∏è GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é CPU")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ LoRA
            active_loras = self.model_manager.get_active_loras(model_type)
            if active_loras:
                self._load_loras(pipe, active_loras, model_type)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º pipeline
            self.current_pipeline = pipe
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º scheduler
            if gen_params["sampler_name"] == "dpmpp_2m":
                pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
                self.logger.info("‚öôÔ∏è –ò—Å–ø–æ–ª—å–∑—É—é DPMSolverMultistepScheduler")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            self.logger.info(f"üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {enhanced_prompt[:50]}...")

            result = pipe(
                prompt=enhanced_prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=gen_params["steps"],
                guidance_scale=gen_params["cfg"],
                width=gen_params["width"],
                height=gen_params["height"],
                generator=torch.Generator(device="cuda" if torch.cuda.is_available() else "cpu").manual_seed(gen_params["seed"])
            )

            # –ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = self._extract_image_from_result(result)
            if image is None:
                raise RuntimeError('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ pipeline')

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            output_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "Images", "generated")
            os.makedirs(output_dir, exist_ok=True)
            
            filename = f"ConsoleTest_{gen_params['seed']}.png"
            output_path = os.path.join(output_dir, filename)
            
            image.save(output_path)
            self.logger.info(f"üíæ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
            
            return output_path
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return None
        finally:
            # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
            if self.current_pipeline:
                del self.current_pipeline
                self.current_pipeline = None
            
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            except:
                pass

    def generate_video(self, prompt: str, negative_prompt: str, params: dict) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ –ø—Ä—è–º—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å–æ Stable Diffusion"""
        start_time = time.time()
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –≤–∏–¥–µ–æ
        default_params = {
            "seed": -1,
            "steps": 20,
            "width": 512,
            "height": 512,
            "cfg": 7.0,
            "num_frames": 24,
            "fps": 8,
            "key_frames": 4
        }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        gen_params = default_params.copy()
        gen_params.update(params)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º seed –µ—Å–ª–∏ –æ–Ω -1
        if gen_params["seed"] == -1:
            gen_params["seed"] = random.randint(0, 2**32 - 1)
            self.logger.info(f"üé≤ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Å–ª—É—á–∞–π–Ω—ã–π seed: {gen_params['seed']}")
        
        self.logger.info(f"üîß –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ: {gen_params}")
        
        try:
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            install_diffusers_dependencies()
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
            from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion import StableDiffusionPipeline
            from diffusers.pipelines.stable_diffusion_xl.pipeline_stable_diffusion_xl import StableDiffusionXLPipeline
            from diffusers.schedulers.scheduling_dpmsolver_multistep import DPMSolverMultistepScheduler
            import torch
            import numpy as np
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
            model_path = self.model_manager.get_model_path()
            if not model_path or not os.path.exists(model_path):
                self.logger.error("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return None
            
            model_type = self.model_manager.detect_model_type(model_path)
            is_sdxl = (model_type == 'sdxl')
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π pipeline
            if is_sdxl:
                self.logger.info("üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ SDXL –º–æ–¥–µ–ª—å, –∏—Å–ø–æ–ª—å–∑—É—é StableDiffusionXLPipeline")
                pipe = StableDiffusionXLPipeline.from_single_file(
                    model_path,
                    torch_dtype=torch.float16,
                    use_safetensors=True
                )
            else:
                self.logger.info("üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ SD 1.5 –º–æ–¥–µ–ª—å, –∏—Å–ø–æ–ª—å–∑—É—é StableDiffusionPipeline")
                pipe = StableDiffusionPipeline.from_single_file(
                    model_path,
                    torch_dtype=torch.float16,
                    use_safetensors=True
                )
            
            if torch.cuda.is_available():
                pipe = pipe.to("cuda")
                self.logger.info("üöÄ –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–º–µ—â–µ–Ω–∞ –Ω–∞ GPU")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º LoRA
            active_loras = self.model_manager.get_active_loras(model_type)
            if active_loras:
                self._load_loras(pipe, active_loras, model_type)
            
            self.current_pipeline = pipe
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º scheduler
            pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            generation_config = {
                "width": gen_params["width"],
                "height": gen_params["height"],
                "num_inference_steps": gen_params["steps"],
                "guidance_scale": gen_params["cfg"],
                "num_images_per_prompt": 1
            }
            
            self.logger.info(f"üé¨ –ì–µ–Ω–µ—Ä–∏—Ä—É—é {gen_params['num_frames']} –∫–∞–¥—Ä–æ–≤ –¥–ª—è –≤–∏–¥–µ–æ...")
            
            frames = []
            key_frames = gen_params["key_frames"]
            
            # –°–æ–∑–¥–∞–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –∫–∞–¥—Ä–æ–≤
            key_prompts = [
                prompt,
                self._add_dynamic_elements(prompt, 1, key_frames),
                self._add_dynamic_elements(prompt, 2, key_frames),
                self._add_dynamic_elements(prompt, 3, key_frames)
            ]
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ –∫–∞–¥—Ä—ã
            for i in range(key_frames):
                seed = gen_params["seed"] + i * 50  # –†–∞–∑–Ω—ã–µ seed'—ã
                generator = torch.Generator(device="cuda" if torch.cuda.is_available() else "cpu").manual_seed(seed)
                
                with torch.no_grad():
                    result = pipe(
                        prompt=key_prompts[i % len(key_prompts)],
                        negative_prompt=negative_prompt,
                        generator=generator,
                        **generation_config
                    )
                
                frame_img = self._extract_image_from_result(result)
                if frame_img is None:
                    raise RuntimeError('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ pipeline')

                frames.append(frame_img)
                self.logger.info(f"  ‚úÖ –ö–ª—é—á–µ–≤–æ–π –∫–∞–¥—Ä {i+1} –≥–æ—Ç–æ–≤")
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–¥—Ä—ã –º–µ–∂–¥—É –∫–ª—é—á–µ–≤—ã–º–∏ –∫–∞–¥—Ä–∞–º–∏
            final_frames = []
            frames_per_segment = gen_params["num_frames"] // (key_frames - 1) if key_frames > 1 else gen_params["num_frames"]
            
            if key_frames > 1:
                for segment in range(key_frames - 1):
                    img1 = np.array(frames[segment])
                    img2 = np.array(frames[segment + 1])
                    
                    for i in range(frames_per_segment):
                        t = i / frames_per_segment
                        t_smooth = 3 * t * t - 2 * t * t * t
                        interpolated_array = img1 * (1 - t_smooth) + img2 * t_smooth
                        interpolated_image = Image.fromarray(interpolated_array.astype(np.uint8))
                        final_frames.append(interpolated_image)
            else:
                final_frames = frames
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–∞–¥—Ä –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            while len(final_frames) < gen_params["num_frames"]:
                final_frames.append(final_frames[-1])
            
            final_frames = final_frames[:gen_params["num_frames"]]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–¥–µ–æ
            output_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "generated_videos")
            os.makedirs(output_dir, exist_ok=True)
            
            filename = f"Video_{gen_params['seed']}.mp4"
            output_path = os.path.join(output_dir, filename)
            
            try:
                import imageio
                imageio.mimsave(output_path, final_frames, fps=gen_params["fps"])
                self.logger.info(f"üíæ –í–∏–¥–µ–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_path}")
                return output_path
            except ImportError:
                self.logger.warning("‚ö†Ô∏è imageio –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —Å–æ—Ö—Ä–∞–Ω—è—é –∫–∞–∫ GIF")
                output_path_gif = output_path.replace(".mp4", ".gif")
                final_frames[0].save(
                    output_path_gif,
                    save_all=True,
                    append_images=final_frames[1:],
                    duration=1000/gen_params["fps"],
                    loop=0
                )
                self.logger.info(f"üíæ GIF —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path_gif}")
                return output_path_gif
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return None
        finally:
            self._unload_current_pipeline()

    def _load_loras(self, pipe, active_loras, model_type):
        """–ó–∞–≥—Ä—É–∑–∫–∞ LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤"""
        self.logger.info(f"üé≠ –ù–∞–π–¥–µ–Ω–æ {len(active_loras)} –∞–∫—Ç–∏–≤–Ω—ã—Ö LoRA –¥–ª—è —Ç–∏–ø–∞ {model_type}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å PEFT
        peft_available = False
        try:
            import peft
            peft_available = True
        except ImportError:
            self.logger.warning("‚ö†Ô∏è PEFT –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, LoRA –º–æ–≥—É—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å")
        
        loaded_loras = []
        for lora in active_loras:
            try:
                lora_filename = lora.get('filename', '')
                lora_strength = lora.get('strength', 1.0)
                lora_path = os.path.join(self.model_manager.lora_dir, model_type, lora_filename)
                
                if not os.path.exists(lora_path):
                    continue
                    
                adapter_name = os.path.splitext(lora_filename)[0]
                
                if lora_filename.endswith('.safetensors'):
                    if not peft_available:
                        continue
                    try:
                        pipe.load_lora_weights(lora_path, adapter_name=adapter_name)
                        loaded_loras.append((adapter_name, lora_strength))
                        self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ LoRA: {lora_filename} ({lora_strength})")
                    except Exception as e:
                        self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ LoRA {lora_filename}: {e}")
                else:
                    try:
                        pipe.load_lora_weights(lora_path)
                        loaded_loras.append((lora_filename, lora_strength))
                        self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ LoRA (legacy): {lora_filename}")
                    except Exception as e:
                        self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ legacy LoRA {lora_filename}: {e}")
                        
            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ LoRA {lora.get('filename')}: {e}")

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–µ—Å–∞
        if loaded_loras and hasattr(pipe, 'set_adapters'):
            try:
                adapter_names = [name for name, _ in loaded_loras]
                adapter_weights = [weight for _, weight in loaded_loras]
                pipe.set_adapters(adapter_names, adapter_weights=adapter_weights)
                self.logger.info(f"‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–µ–Ω—ã –≤–µ—Å–∞ –∞–¥–∞–ø—Ç–µ—Ä–æ–≤")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –≤–µ—Å–∞ –∞–¥–∞–ø—Ç–µ—Ä–æ–≤: {e}")

    def _extract_image_from_result(self, result) -> Optional[Image.Image]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç PIL Image –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ pipeline"""
        try:
            imgs = getattr(result, 'images', None)
            if imgs:
                return imgs[0]
            elif isinstance(result, (tuple, list)) and len(result) > 0:
                return result[0]
        except Exception:
            pass
        return None

    def _unload_current_pipeline(self):
        """–í—ã–≥—Ä—É–∂–∞–µ—Ç —Ç–µ–∫—É—â–∏–π pipeline –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ VRAM"""
        try:
            if hasattr(self, 'current_pipeline') and self.current_pipeline is not None:
                self.logger.info("üîÑ –í—ã–≥—Ä—É–∂–∞—é pipeline –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ VRAM...")
                
                # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–∞ CPU
                if hasattr(self.current_pipeline, 'to'):
                    self.current_pipeline.to('cpu')
                
                # –£–¥–∞–ª—è–µ–º pipeline
                del self.current_pipeline
                self.current_pipeline = None
                
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ GPU
                try:
                    import torch
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                        self.logger.info("üßπ –û—á–∏—â–µ–Ω –∫—ç—à CUDA")
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å CUDA –∫—ç—à: {e}")
                
                self.logger.info("‚úÖ Pipeline –≤—ã–≥—Ä—É–∂–µ–Ω")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤—ã–≥—Ä—É–∑–∫–∏ pipeline: {e}")

    def _is_realesrgan_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ RealESRGAN"""
        try:
            base_dir = os.path.dirname(os.path.abspath(__file__))
            model_path = os.path.join(base_dir, "stable_diff", "RealESRGAN_x4.pth")
            return os.path.exists(model_path)
        except Exception:
            return False

    def upscale_image_realesrgan(self, image_path: str, output_path: Optional[str] = None) -> Optional[str]:
        """
        –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ 4 —Ä–∞–∑–∞ —Å –ø–æ–º–æ—â—å—é RealESRGAN
        """
        try:
            self.logger.info(f"üìà –ù–∞—á–∏–Ω–∞—é –∞–ø—Å–∫–µ–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {os.path.basename(image_path)}")
            
            # –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ RealESRGAN
            base_dir = os.path.dirname(os.path.abspath(__file__))
            model_path = os.path.join(base_dir, "stable_diff", "RealESRGAN_x4.pth")
            
            if not os.path.exists(model_path):
                self.logger.info(f"‚ÑπÔ∏è –ú–æ–¥–µ–ª—å RealESRGAN –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
                return None
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            if not os.path.exists(image_path):
                self.logger.error(f"‚ùå –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {image_path}")
                return None
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π –ø—É—Ç—å
            if output_path is None:
                base_name = os.path.splitext(os.path.basename(image_path))[0]
                output_dir = os.path.dirname(image_path)
                output_path = os.path.join(output_dir, f"{base_name}_upscaled_4x.png")
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Real-ESRGAN –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            self._install_realesrgan_dependencies()
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
            try:
                import cv2
                import torch
                import numpy as np
                from PIL import Image
                
                # –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å RealESRGAN
                try:
                    from realesrgan import RealESRGANer
                    from basicsr.archs.rrdbnet_arch import RRDBNet
                except ImportError:
                    self.logger.warning("‚ö†Ô∏è realesrgan –ø–∞–∫–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥")
                    return self._upscale_image_alternative(image_path, output_path)
                
                # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
                model = RRDBNet(
                    num_in_ch=3, 
                    num_out_ch=3, 
                    num_feat=64, 
                    num_block=23, 
                    num_grow_ch=32, 
                    scale=4
                )
                
                # –°–æ–∑–¥–∞–µ–º upsampler
                upsampler = RealESRGANer(
                    scale=4,
                    model_path=model_path,
                    model=model,
                    tile=0,
                    tile_pad=10,
                    pre_pad=0,
                    half=torch.cuda.is_available()
                )
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                img = cv2.imread(image_path, cv2.IMREAD_COLOR)
                if img is None:
                    raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
                
                self.logger.info(f"üìê –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {img.shape[1]}x{img.shape[0]}")
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–ø—Å–∫–µ–π–ª
                self.logger.info("üöÄ –í—ã–ø–æ–ª–Ω—è—é –∞–ø—Å–∫–µ–π–ª...")
                output, _ = upsampler.enhance(img, outscale=4)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                cv2.imwrite(output_path, output)
                
                self.logger.info(f"üìê –†–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–π —Ä–∞–∑–º–µ—Ä: {output.shape[1]}x{output.shape[0]}")
                self.logger.info(f"üíæ –ê–ø—Å–∫–µ–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
                
                return output_path
                
            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∞–ø—Å–∫–µ–π–ª–∞: {e}")
                return self._upscale_image_alternative(image_path, output_path)
                
        except Exception as e:
            self.logger.error(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞ –∞–ø—Å–∫–µ–π–ª–∞: {e}")
            return None
    
    def _upscale_image_alternative(self, image_path: str, output_path: str) -> Optional[str]:
        """
        –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∞–ø—Å–∫–µ–π–ª–∞ —Å –ø–æ–º–æ—â—å—é –ø—Ä–æ—Å—Ç–æ–≥–æ –±–∏–∫—É–±–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        try:
            self.logger.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∞–ø—Å–∫–µ–π–ª–∞...")
            
            from PIL import Image
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            with Image.open(image_path) as img:
                original_size = img.size
                new_size = (original_size[0] * 4, original_size[1] * 4)
                
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å –ø–æ–º–æ—â—å—é –±–∏–∫—É–±–∏—á–µ—Å–∫–æ–π –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏
                upscaled = img.resize(new_size, Image.Resampling.LANCZOS)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                upscaled.save(output_path, "PNG")
                
                self.logger.info(f"üìê –£–≤–µ–ª–∏—á–µ–Ω–æ —Å {original_size} –¥–æ {new_size}")
                self.logger.info(f"üíæ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∞–ø—Å–∫–µ–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
                
                return output_path
                
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –∞–ø—Å–∫–µ–π–ª–∞: {e}")
            return None
    
    def _add_dynamic_elements(self, prompt, frame_index, total_frames):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∫ –ø—Ä–æ–º–ø—Ç—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–æ–º–µ—Ä–∞ –∫–∞–¥—Ä–∞"""
        
        # –ë–∞–∑–æ–≤—ã–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø—Ä–æ–º–ø—Ç–æ–≤
        dynamic_elements = {
            "pose": [
                "slight head turn", "head turning", "looking to the side", "looking up", "looking down",
                "slight body movement", "body turning", "arm movement", "hand gesture", "finger movement",
                "eye movement", "blinking", "mouth movement", "smile change", "expression change"
            ],
            "lighting": [
                "slight lighting change", "light shift", "shadow movement", "highlight change",
                "ambient light variation", "light intensity change", "color temperature shift"
            ],
            "camera": [
                "slight camera movement", "camera angle change", "zoom effect", "perspective shift",
                "depth change", "focus adjustment", "blur variation"
            ],
            "motion": [
                "motion blur", "movement lines", "wind effect", "hair movement", "clothing movement",
                "particle effects", "energy flow", "magical effects", "sparkle effects"
            ]
        }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø—Ä–æ–º–ø—Ç–∞
        prompt_lower = prompt.lower()
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        if any(word in prompt_lower for word in ["anime", "girl", "boy", "character", "person"]):
            # –î–ª—è –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –¥–æ–±–∞–≤–ª—è–µ–º –¥–≤–∏–∂–µ–Ω–∏—è –∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
            elements = dynamic_elements["pose"] + dynamic_elements["motion"]
        elif any(word in prompt_lower for word in ["landscape", "nature", "scenery", "background"]):
            # –î–ª—è –ø–µ–π–∑–∞–∂–µ–π –¥–æ–±–∞–≤–ª—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ—Å–≤–µ—â–µ–Ω–∏—è –∏ –∫–∞–º–µ—Ä—ã
            elements = dynamic_elements["lighting"] + dynamic_elements["camera"]
        else:
            # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã
            elements = dynamic_elements["pose"] + dynamic_elements["lighting"] + dynamic_elements["camera"] + dynamic_elements["motion"]
        
        # –í—ã–±–∏—Ä–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–æ–º–µ—Ä–∞ –∫–∞–¥—Ä–∞
        if elements:
            # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ –∫–∞–¥—Ä–∞–º
            element_index = int((frame_index / total_frames) * len(elements))
            selected_element = elements[element_index % len(elements)]
            
            # –î–æ–±–∞–≤–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç –∫ –ø—Ä–æ–º–ø—Ç—É
            enhanced_prompt = f"{prompt}, {selected_element}"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            progress = frame_index / total_frames
            if progress > 0.5:
                enhanced_prompt += ", subtle animation"
            
            return enhanced_prompt
        
        return prompt

    def _install_realesrgan_dependencies(self):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è RealESRGAN"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏ basicsr
            try:
                import basicsr
            except ImportError:
                self.logger.info("üì¶ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é basicsr...")
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'basicsr'], 
                             check=True, capture_output=True)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏ realesrgan
            try:
                import realesrgan
            except ImportError:
                self.logger.info("üì¶ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é realesrgan...")
                subprocess.run([sys.executable, '-m', 'pip', 'install', 'realesrgan'], 
                             check=True, capture_output=True)
                             
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ RealESRGAN: {e}")
        

class ModelManager:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è Stable Diffusion –º–æ–¥–µ–ª—è–º–∏ –∏ LoRA
    """
    
    def __init__(self, base_dir: str | None = None):
        if base_dir is None:
            base_dir = os.path.dirname(os.path.abspath(__file__))
        
        self.base_dir = base_dir
        self.stable_diff_dir = os.path.join(base_dir, "stable_diff")
        self.checkpoints_dir = os.path.join(self.stable_diff_dir, "checkpoints")
        self.lora_dir = os.path.join(self.stable_diff_dir, "lora")
        self.lora_config_path = os.path.join(self.lora_dir, "lora_config.json")
        
        # –ö—ç—à –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ LoRA
        self._lora_config_cache = {}
        self._lora_config_last_modified = 0
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        self._ensure_directories()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é LoRA
        self._init_lora_config()
    
    def _ensure_directories(self):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç"""
        os.makedirs(self.checkpoints_dir, exist_ok=True)
        os.makedirs(os.path.join(self.lora_dir, "sd"), exist_ok=True)
        os.makedirs(os.path.join(self.lora_dir, "sdxl"), exist_ok=True)
    
    def _init_lora_config(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é LoRA"""
        if not os.path.exists(self.lora_config_path):
            self._generate_lora_config()
        else:
            self._scan_and_update_lora_config()
    
    def _scan_lora_files(self) -> Dict[str, List[str]]:
        """–°–∫–∞–Ω–∏—Ä—É–µ—Ç –ø–∞–ø–∫–∏ LoRA –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"""
        lora_files = {"sd": [], "sdxl": []}
        
        for model_type in ["sd", "sdxl"]:
            lora_type_dir = os.path.join(self.lora_dir, model_type)
            if os.path.exists(lora_type_dir):
                for file in os.listdir(lora_type_dir):
                    if file.lower().endswith(('.safetensors', '.ckpt', '.pt')):
                        lora_files[model_type].append(file)
        
        return lora_files
    
    def _generate_lora_config(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –±–∞–∑–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é LoRA"""
        lora_files = self._scan_lora_files()
        config = {"loras": {}}
        
        for model_type, files in lora_files.items():
            for filename in files:
                lora_name = os.path.splitext(filename)[0]
                config["loras"][f"{model_type}_{lora_name}"] = {
                    "filename": filename,
                    "model_type": model_type,
                    "enabled": True,
                    "strength": 1.0,
                    "triggers": [],
                    "description": f"Auto-generated config for {filename}"
                }
        
        with open(self.lora_config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        
        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª LoRA: {len(config['loras'])} —Ñ–∞–π–ª–æ–≤")
    
    def _scan_and_update_lora_config(self):
        """–°–∫–∞–Ω–∏—Ä—É–µ—Ç LoRA —Ñ–∞–π–ª—ã –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –Ω–æ–≤—ã–º–∏ —Å –∞–Ω–∞–ª–∏–∑–æ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        lora_files = self._scan_lora_files()
        
        try:
            with open(self.lora_config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except:
            config = {"loras": {}}
        
        if "loras" not in config:
            config["loras"] = {}
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ LoRA —Ñ–∞–π–ª—ã
        updated = False
        for model_type, files in lora_files.items():
            for filename in files:
                lora_name = os.path.splitext(filename)[0]
                lora_key = f"{model_type}_{lora_name}"
                
                if lora_key not in config["loras"]:
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ LoRA
                    lora_path = os.path.join(self.lora_dir, model_type, filename)
                    metadata = self.analyze_lora_metadata(lora_path)
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–ø–∫—É
                    detected_model_type = metadata.get("model_type", model_type)
                    if detected_model_type != "unknown" and detected_model_type != model_type:
                        logger.warning(f"‚ö†Ô∏è LoRA {filename} –≤ –ø–∞–ø–∫–µ {model_type}/, –Ω–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ {detected_model_type}")
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∏–ø –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∫–∞–∫ –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π
                        actual_model_type = detected_model_type
                        lora_key = f"{actual_model_type}_{lora_name}"
                    else:
                        actual_model_type = model_type
                    
                    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
                    config["loras"][lora_key] = {
                        "filename": filename,
                        "model_type": actual_model_type,
                        "enabled": True,
                        "strength": metadata.get("preferred_weight", 1.0),
                        "triggers": metadata.get("triggers", [])[:3],  # –ë–µ—Ä–µ–º —Ç–æ–ø-3 —Ç—Ä–∏–≥–≥–µ—Ä–∞
                        "description": metadata.get("description", f"Auto-detected: {metadata.get('base_model', 'Unknown')} LoRA"),
                        "base_model": metadata.get("base_model", "Unknown"),
                        "resolution": metadata.get("resolution", "Unknown"),
                        "author": metadata.get("author", ""),
                        "metadata_analyzed": True
                    }
                    updated = True
                    
                    logger.info(f"üìã –°–æ–∑–¥–∞–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è {filename}")
                    logger.info(f"   üéØ –¢–∏–ø: {actual_model_type} ({metadata.get('base_model', 'Unknown')})")
                    if metadata.get("triggers"):
                        logger.info(f"   üî§ –¢—Ä–∏–≥–≥–µ—Ä—ã: {', '.join(metadata['triggers'][:3])}")
        
        if updated:
            with open(self.lora_config_path, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª LoRA —Å –∞–Ω–∞–ª–∏–∑–æ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")
    
    def get_lora_config(self, force_reload: bool = False) -> Dict:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é LoRA —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞
            if os.path.exists(self.lora_config_path):
                mtime = os.path.getmtime(self.lora_config_path)
                
                # –ï—Å–ª–∏ —Ñ–∞–π–ª –∏–∑–º–µ–Ω–∏–ª—Å—è –∏–ª–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞
                if force_reload or mtime > self._lora_config_last_modified:
                    with open(self.lora_config_path, 'r', encoding='utf-8') as f:
                        self._lora_config_cache = json.load(f)
                    self._lora_config_last_modified = mtime
                    logger.info("üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LoRA")
                
                return self._lora_config_cache
            else:
                return {"loras": {}}
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ LoRA: {e}")
            return {"loras": {}}
    
    def analyze_lora_metadata(self, lora_path: str) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ LoRA —Ñ–∞–π–ª–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        
        Args:
            lora_path: –ü—É—Ç—å –∫ LoRA —Ñ–∞–π–ª—É
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ LoRA
        """
        try:
            from safetensors import safe_open
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            metadata = {
                "model_type": "unknown",
                "base_model": "unknown", 
                "resolution": "unknown",
                "triggers": [],
                "description": "",
                "author": "",
                "version": "",
                "activation_text": "",
                "preferred_weight": 1.0
            }
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
            file_ext = os.path.splitext(lora_path)[1].lower()
            
            if file_ext == ".safetensors":
                # –ß–∏—Ç–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ safetensors
                with safe_open(lora_path, framework="pt") as f:
                    metadata_raw = f.metadata()
                    
                    if metadata_raw:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
                        if "ss_base_model_version" in metadata_raw:
                            base_version = metadata_raw["ss_base_model_version"]
                            if "xl" in base_version.lower():
                                metadata["model_type"] = "sdxl"
                                metadata["base_model"] = "SDXL"
                            else:
                                metadata["model_type"] = "sd"
                                metadata["base_model"] = "SD 1.5"
                        
                        # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
                        if "ss_resolution" in metadata_raw:
                            metadata["resolution"] = metadata_raw["ss_resolution"]
                        elif "ss_bucket_info" in metadata_raw:
                            try:
                                bucket_info = json.loads(metadata_raw["ss_bucket_info"])
                                if "buckets" in bucket_info:
                                    resolutions = list(bucket_info["buckets"].keys())
                                    if resolutions:
                                        metadata["resolution"] = resolutions[0]
                            except:
                                pass
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–≥–∏ –∏ —Ç—Ä–∏–≥–≥–µ—Ä—ã
                        if "ss_tag_frequency" in metadata_raw:
                            try:
                                tag_freq = json.loads(metadata_raw["ss_tag_frequency"])
                                # –ü–æ–ª—É—á–∞–µ–º —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ —Ç–µ–≥–∏ –∫–∞–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã
                                all_tags = {}
                                for dataset_tags in tag_freq.values():
                                    all_tags.update(dataset_tags)
                                
                                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ –∏ –±–µ—Ä–µ–º —Ç–æ–ø-5
                                sorted_tags = sorted(all_tags.items(), key=lambda x: x[1], reverse=True)
                                metadata["triggers"] = [tag for tag, _ in sorted_tags[:5]]
                            except:
                                pass
                        
                        # –î—Ä—É–≥–∏–µ –ø–æ–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                        metadata_mapping = {
                            "ss_dataset_dirs": "description",
                            "modelspec.architecture": "architecture",
                            "modelspec.implementation": "implementation",
                            "modelspec.title": "title"
                        }
                        
                        for key, target in metadata_mapping.items():
                            if key in metadata_raw:
                                metadata[target] = metadata_raw[key]
                        
                        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∞–≤—Ç–æ—Ä–∞ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
                        filename = os.path.basename(lora_path)
                        if "_" in filename or "-" in filename:
                            parts = filename.replace("_", " ").replace("-", " ").split()
                            metadata["author"] = parts[0] if parts else ""
                        
                        logger.info(f"üîç –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ LoRA: {filename}")
                        logger.info(f"   üìã –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: {metadata['base_model']}")
                        logger.info(f"   üìê –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {metadata['resolution']}")
                        if metadata["triggers"]:
                            logger.info(f"   üéØ –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã: {', '.join(metadata['triggers'][:3])}")
            
            elif file_ext in [".ckpt", ".pt"]:
                # –î–ª—è —Å—Ç–∞—Ä—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
                filename = os.path.basename(lora_path).lower()
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                if any(keyword in filename for keyword in ["sdxl", "xl", "illustrious", "pony"]):
                    metadata["model_type"] = "sdxl"
                    metadata["base_model"] = "SDXL"
                else:
                    metadata["model_type"] = "sd"
                    metadata["base_model"] = "SD 1.5"
                
                logger.info(f"üîç –ê–Ω–∞–ª–∏–∑ LoRA –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞: {metadata['base_model']}")
            
            return metadata
            
        except ImportError:
            logger.warning("‚ö†Ô∏è safetensors –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return {"model_type": "unknown", "error": "safetensors not available"}
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö LoRA {lora_path}: {e}")
            return {"model_type": "unknown", "error": str(e)}
    
    def get_model_path(self) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º .env > stable_diff"""
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è
        env_path = os.getenv('STABLE_DIFFUSION_MODEL_PATH', '').strip()
        if env_path and os.path.exists(env_path):
            return env_path
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –ø–∞–ø–∫–∞ stable_diff/checkpoints
        if os.path.exists(self.checkpoints_dir):
            for file in os.listdir(self.checkpoints_dir):
                if file.lower().endswith(('.safetensors', '.ckpt')):
                    model_path = os.path.join(self.checkpoints_dir, file)
                    logger.info(f"üîç –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å: {file}")
                    return model_path
        
        # Fallback: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Ç—å –∏–∑ .env –¥–∞–∂–µ –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        return env_path if env_path else ""
    
    def detect_model_type(self, model_path: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –º–æ–¥–µ–ª–∏ (sd/sdxl) –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º –∏–ª–∏ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        
        Args:
            model_path: –ü—É—Ç—å –∫ checkpoint —Ñ–∞–π–ª—É
            
        Returns:
            –¢–∏–ø –º–æ–¥–µ–ª–∏: 'sd' –∏–ª–∏ 'sdxl'
        """
        if not os.path.exists(model_path):
            logger.warning(f"‚ö†Ô∏è –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}")
            return 'sd'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é SD 1.5
        
        file_ext = os.path.splitext(model_path)[1].lower()
        model_name = os.path.basename(model_path).lower()
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        if file_ext == ".safetensors":
            try:
                metadata = self.analyze_checkpoint_metadata(model_path)
                detected_type = metadata.get("model_type", "unknown")
                
                if detected_type != "unknown":
                    logger.info(f"üîç –¢–∏–ø –º–æ–¥–µ–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º: {detected_type}")
                    return detected_type
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö checkpoint: {e}")
        
        # –†–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        if any(keyword in model_name for keyword in ['sdxl', 'xl', 'illustrious', 'pony']):
            logger.info(f"üîç –¢–∏–ø –º–æ–¥–µ–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞: sdxl")
            return 'sdxl'
        else:
            logger.info(f"üîç –¢–∏–ø –º–æ–¥–µ–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞: sd")
            return 'sd'
    
    def analyze_checkpoint_metadata(self, checkpoint_path: str) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ checkpoint —Ñ–∞–π–ª–∞
        
        Args:
            checkpoint_path: –ü—É—Ç—å –∫ checkpoint —Ñ–∞–π–ª—É
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ checkpoint
        """
        try:
            from safetensors import safe_open
            
            metadata = {
                "model_type": "unknown",
                "architecture": "unknown",
                "base_model": "unknown",
                "resolution": "unknown",
                "model_name": "",
                "author": "",
                "description": "",
                "version": ""
            }
            
            file_ext = os.path.splitext(checkpoint_path)[1].lower()
            
            if file_ext == ".safetensors":
                with safe_open(checkpoint_path, framework="pt") as f:
                    metadata_raw = f.metadata()
                    tensor_keys = list(f.keys())
                    
                    logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(tensor_keys)} —Ç–µ–Ω–∑–æ—Ä–æ–≤ –≤ checkpoint")
                    if metadata_raw:
                        logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(metadata_raw)} –∑–∞–ø–∏—Å–µ–π –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª—é—á–∏ —Ç–µ–Ω–∑–æ—Ä–æ–≤ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
                    sdxl_indicators = [
                        "conditioner.embedders.1.model.transformer.resblocks",
                        "conditioner.embedders.0.transformer.text_model",
                        "first_stage_model.encoder.down.0.block.0.norm1.weight",
                        "model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight"
                    ]
                    
                    sd_indicators = [
                        "cond_stage_model.transformer.text_model.encoder.layers",
                        "first_stage_model.encoder.down.0.block.0.norm1.weight",
                        "model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight"
                    ]
                    
                    # –ò—â–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –∫–ª—é—á–∏ –¥–ª—è SDXL
                    sdxl_score = 0
                    sd_score = 0
                    
                    for key in tensor_keys[:100]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 100 –∫–ª—é—á–µ–π
                        for indicator in sdxl_indicators:
                            if indicator in key:
                                sdxl_score += 1
                                break
                        
                        for indicator in sd_indicators:
                            if indicator in key and "conditioner.embedders.1" not in key:
                                sd_score += 1
                                break
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ä–∞–∑–º–µ—Ä–∞–º –º–æ–¥–µ–ª–µ–π
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —ç–Ω–∫–æ–¥–µ—Ä–∞
                        text_encoder_keys = [k for k in tensor_keys if "text_model.embeddings.token_embedding.weight" in k]
                        if text_encoder_keys:
                            tensor = f.get_tensor(text_encoder_keys[0])
                            vocab_size = tensor.shape[0]
                            logger.info(f"üîç –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —ç–Ω–∫–æ–¥–µ—Ä–∞: {vocab_size}")
                            
                            if vocab_size > 50000:  # SDXL –æ–±—ã—á–Ω–æ –∏–º–µ–µ—Ç –±–æ–ª—å—à–∏–π —Å–ª–æ–≤–∞—Ä—å
                                sdxl_score += 2
                            else:
                                sd_score += 2
                    except:
                        pass
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã UNet
                    try:
                        unet_keys = [k for k in tensor_keys if "model.diffusion_model.input_blocks.0.0.weight" in k]
                        if unet_keys:
                            tensor = f.get_tensor(unet_keys[0])
                            input_channels = tensor.shape[1]
                            logger.info(f"üîç –í—Ö–æ–¥–Ω—ã–µ –∫–∞–Ω–∞–ª—ã UNet: {input_channels}")
                            
                            if input_channels == 4:  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ –¥–ª—è –æ–±–µ–∏—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—Ä—É–≥–∏–µ —Ä–∞–∑–º–µ—Ä—ã
                                output_channels = tensor.shape[0]
                                if output_channels >= 320:
                                    sdxl_score += 1
                    except:
                        pass
                    
                    logger.info(f"üîç –°—á–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è: SDXL={sdxl_score}, SD={sd_score}")
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—á–µ—Ç–∞
                    if sdxl_score > sd_score:
                        metadata["model_type"] = "sdxl"
                        metadata["architecture"] = "SDXL"
                        metadata["base_model"] = "SDXL"
                        metadata["resolution"] = "1024x1024"
                    elif sd_score > 0:
                        metadata["model_type"] = "sd"
                        metadata["architecture"] = "SD 1.5"
                        metadata["base_model"] = "SD 1.5"
                        metadata["resolution"] = "512x512"
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Ñ–∞–π–ª–∞
                    if metadata_raw:
                        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ–ª—è
                        standard_fields = {
                            "modelspec.title": "model_name",
                            "modelspec.description": "description", 
                            "modelspec.author": "author",
                            "modelspec.implementation": "implementation",
                            "modelspec.architecture": "architecture_info"
                        }
                        
                        for raw_key, meta_key in standard_fields.items():
                            if raw_key in metadata_raw:
                                metadata[meta_key] = metadata_raw[raw_key]
                        
                        # –ò—â–µ–º –¥—Ä—É–≥–∏–µ –ø–æ–ª–µ–∑–Ω—ã–µ –ø–æ–ª—è
                        for key, value in metadata_raw.items():
                            if "title" in key.lower() and not metadata.get("model_name"):
                                metadata["model_name"] = value
                            elif "description" in key.lower() and not metadata.get("description"):
                                metadata["description"] = value
                            elif "author" in key.lower() and not metadata.get("author"):
                                metadata["author"] = value
                    
                    logger.info(f"üîç –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞: {metadata['model_type']}")
                    if metadata["model_type"] != "unknown":
                        logger.info(f"   üìã –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {metadata['architecture']}")
                        logger.info(f"   üìê –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {metadata['resolution']}")
                        
                        if metadata.get("model_name"):
                            logger.info(f"   üìù –ù–∞–∑–≤–∞–Ω–∏–µ: {metadata['model_name']}")
                    
            return metadata
            
        except ImportError:
            logger.warning("‚ö†Ô∏è safetensors –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∞–Ω–∞–ª–∏–∑ checkpoint –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return {"model_type": "unknown", "error": "safetensors not available"}
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö checkpoint {checkpoint_path}: {e}")
            return {"model_type": "unknown", "error": str(e)}
    
    def get_active_loras(self, model_type: str) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö LoRA –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏"""
        config = self.get_lora_config()
        active_loras = []
        
        for lora_key, lora_config in config.get("loras", {}).items():
            if (lora_config.get("enabled", False) and 
                lora_config.get("model_type") == model_type):
                active_loras.append(lora_config)
        
        return active_loras
    
    def apply_lora_triggers(self, prompt: str, model_type: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ç—Ä–∏–≥–≥–µ—Ä-—Å–ª–æ–≤–∞ LoRA –∫ –ø—Ä–æ–º–ø—Ç—É"""
        active_loras = self.get_active_loras(model_type)
        triggers = []
        
        for lora in active_loras:
            lora_triggers = lora.get("triggers", [])
            if lora_triggers:
                triggers.extend(lora_triggers)
        
        if triggers:
            trigger_text = ", ".join(triggers)
            enhanced_prompt = f"{prompt}, {trigger_text}"
            logger.info(f"üéØ –î–æ–±–∞–≤–ª–µ–Ω—ã LoRA —Ç—Ä–∏–≥–≥–µ—Ä—ã: {trigger_text}")
            return enhanced_prompt
        
        return prompt
    
    def analyze_all_loras(self) -> Dict[str, Dict[str, Any]]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤—Å–µ—Ö LoRA —Ñ–∞–π–ª–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞ –≤—Å–µ—Ö LoRA
        """
        results = {}
        lora_files = self._scan_lora_files()
        
        logger.info("üîç –ó–∞–ø—É—Å–∫–∞—é –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤—Å–µ—Ö LoRA —Ñ–∞–π–ª–æ–≤...")
        
        for model_type, files in lora_files.items():
            for filename in files:
                lora_path = os.path.join(self.lora_dir, model_type, filename)
                lora_key = f"{model_type}_{os.path.splitext(filename)[0]}"
                
                logger.info(f"üìã –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é: {filename}")
                metadata = self.analyze_lora_metadata(lora_path)
                
                results[lora_key] = {
                    "filename": filename,
                    "path": lora_path,
                    "folder_type": model_type,
                    "detected_type": metadata.get("model_type", "unknown"),
                    "base_model": metadata.get("base_model", "Unknown"),
                    "resolution": metadata.get("resolution", "Unknown"),
                    "triggers": metadata.get("triggers", []),
                    "author": metadata.get("author", ""),
                    "description": metadata.get("description", ""),
                    "compatible": metadata.get("model_type", model_type) == model_type,
                    "analysis_success": "error" not in metadata
                }
                
                # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏
                if (metadata.get("model_type", "unknown") != "unknown" and 
                    metadata.get("model_type") != model_type):
                    logger.warning(f"‚ö†Ô∏è {filename}: –≤ –ø–∞–ø–∫–µ {model_type}/, –Ω–æ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è {metadata.get('model_type')}")
        
        logger.info(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(results)} LoRA —Ñ–∞–π–ª–æ–≤")
        return results
    
    def update_lora_metadata(self, force_update: bool = False) -> bool:
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö LoRA –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        
        Args:
            force_update: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –≤—Å–µ LoRA (–¥–∞–∂–µ —É–∂–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
            
        Returns:
            True –µ—Å–ª–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±—ã–ª–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞
        """
        try:
            config = self.get_lora_config(force_reload=True)
            if "loras" not in config:
                config["loras"] = {}
            
            updated = False
            
            for lora_key, lora_config in config["loras"].items():
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ LoRA (–µ—Å–ª–∏ –Ω–µ force_update)
                if not force_update and lora_config.get("metadata_analyzed", False):
                    continue
                
                filename = lora_config.get("filename")
                model_type = lora_config.get("model_type", "sd")
                
                if not filename:
                    continue
                
                # –ò—â–µ–º —Ñ–∞–π–ª –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π –ø–∞–ø–∫–µ
                lora_path = os.path.join(self.lora_dir, model_type, filename)
                
                if not os.path.exists(lora_path):
                    logger.warning(f"‚ö†Ô∏è LoRA —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {lora_path}")
                    continue
                
                logger.info(f"üîç –û–±–Ω–æ–≤–ª—è—é –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è {filename}")
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                metadata = self.analyze_lora_metadata(lora_path)
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏
                detected_type = metadata.get("model_type", model_type)
                if detected_type != "unknown" and detected_type != model_type:
                    logger.warning(f"‚ö†Ô∏è LoRA {filename} –≤ –ø–∞–ø–∫–µ {model_type}/, –Ω–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ {detected_type}")
                    actual_model_type = detected_type
                    
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –∫–ª—é—á —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ç–∏–ø–æ–º
                    new_lora_key = f"{actual_model_type}_{os.path.splitext(filename)[0]}"
                    if new_lora_key != lora_key:
                        logger.info(f"üîÑ –ü–µ—Ä–µ–º–µ—â–∞—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é: {lora_key} -> {new_lora_key}")
                        # –ö–æ–ø–∏—Ä—É–µ–º –≤ –Ω–æ–≤—ã–π –∫–ª—é—á
                        config["loras"][new_lora_key] = lora_config.copy()
                        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π –∫–ª—é—á
                        del config["loras"][lora_key]
                        lora_key = new_lora_key
                        lora_config = config["loras"][lora_key]
                else:
                    actual_model_type = model_type
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                user_enabled = lora_config.get("enabled", True)
                user_strength = lora_config.get("strength", 1.0)
                user_triggers = lora_config.get("triggers", [])
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
                config["loras"][lora_key].update({
                    "model_type": actual_model_type,
                    "enabled": user_enabled,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É
                    "strength": user_strength,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫—É—é —Å–∏–ª—É
                    "triggers": user_triggers if user_triggers else metadata.get("triggers", [])[:3],
                    "description": metadata.get("description", f"Auto-detected: {metadata.get('base_model', 'Unknown')} LoRA"),
                    "base_model": metadata.get("base_model", "Unknown"),
                    "resolution": metadata.get("resolution", "Unknown"),
                    "author": metadata.get("author", ""),
                    "metadata_analyzed": True
                })
                
                updated = True
                
                logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è {filename}")
                logger.info(f"   üéØ –¢–∏–ø: {actual_model_type} ({metadata.get('base_model', 'Unknown')})")
                if metadata.get("triggers") and not user_triggers:
                    logger.info(f"   üî§ –ù–æ–≤—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã: {', '.join(metadata['triggers'][:3])}")
            
            if updated:
                with open(self.lora_config_path, 'w', encoding='utf-8') as f:
                    json.dump(config, f, ensure_ascii=False, indent=2)
                logger.info(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LoRA –æ–±–Ω–æ–≤–ª–µ–Ω–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏")
                return True
            else:
                logger.info(f"üìã –í—Å–µ LoRA —É–∂–µ –∏–º–µ—é—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö LoRA: {e}")
            return False



__all__ = ["ModelManager", "ImageGenerator"]
