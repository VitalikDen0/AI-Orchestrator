# Beta-песочница

Папка `beta/` — площадка для быстрого прототипирования экспериментальных функций перед тем, как переносить их в основной код. Всё, что находится здесь, может меняться и ломаться; документацию к каждому прототипу ведём прямо в этом файле.

## Текущие прототипы

### 1) Прототип генерации видео по тексту

- Идея целевой модели: **Wan 2.2** (или аналогичная SOTA text-to-video). Пока используем лёгкий заглушечный пайплайн для проверки конвейера.
- Вход: текстовый промт из консоли.
- Выход: mp4 в `beta/output/` (если есть `ffmpeg` в PATH). Если `ffmpeg` недоступен — кадры сохранятся как PNG в той же папке.
- Дефолты: 24 кадра, 8 fps для быстрой проверки.
- Логирование: INFO/DEBUG в консоль с таймингами этапов.

#### Запуск

1) Активировать venv
2) Выполнить:

```bash
python beta/video_generation_beta.py --prompt "A calm sunset over the sea"
```

Параметры можно изменить: `--frames`, `--fps`, `--seed`, `--output`.

#### Зависимости

- `ffmpeg` в системе (для сборки mp4). Без него сохраняются отдельные PNG.
- Python-библиотеки: `Pillow`, `imageio`, `numpy` (уже используются в проекте; ставятся из `requirements.txt`).

#### Что проверить

- Быстро ли собирается конвейер.
- Есть ли нужные артефакты (mp4 или кадры).
- Устроен ли формат логов и CLI.

#### Куда двигаться дальше

- Подключить реальную text-to-video модель (Wan 2.2 / AnimateDiff-подобные) с GPU.
- Добавить управление параметрами качества, шагами денойзинга и контроллерами движения.
- Интегрировать в основной pipeline после стабилизации.
